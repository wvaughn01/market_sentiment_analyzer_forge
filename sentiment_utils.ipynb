{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93159f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from newsapi import NewsApiClient\n",
    "import streamlit as st\n",
    "\n",
    "# Only import API clients if we're not in mock mode\n",
    "USE_MOCK = os.environ.get('USE_MOCK_SCRAPE', '0') == '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ec99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialNewsAggregator:\n",
    "    def __init__(self, alpha_vantage_key=None, newsapi_key=None, use_mock=None):\n",
    "        \"\"\"\n",
    "        Initialize with API keys. If keys are not provided, will attempt to read from environment variables:\n",
    "        ALPHA_VANTAGE_KEY, NEWS_API_KEY\n",
    "        \"\"\"\n",
    "        self.use_mock = use_mock if use_mock is not None else os.environ.get('USE_MOCK_SCRAPE', '0') == '1'\n",
    "        \n",
    "        if not self.use_mock:\n",
    "            self.alpha_vantage_key = alpha_vantage_key or st.secrets.get(\"ALPHA_VANTAGE_API_KEY\")\n",
    "            self.newsapi_key = newsapi_key or st.secrets.get(\"NEWS_API_KEY\")\n",
    "\n",
    "            \n",
    "            # Initialize NewsAPI client if key is available\n",
    "            if self.newsapi_key:\n",
    "                self.newsapi_client = NewsApiClient(api_key=self.newsapi_key)\n",
    "            \n",
    "        self.analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ddc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newsapi_articles(self, ticker, days_back=7):\n",
    "    if not self.newsapi_key:\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "        response = self.newsapi_client.get_everything(\n",
    "            q=ticker,\n",
    "            from_param=start_date.strftime('%Y-%m-%d'),\n",
    "            to=end_date.strftime('%Y-%m-%d'),\n",
    "            language='en',\n",
    "            sort_by='relevancy'\n",
    "        )\n",
    "        if not response or 'articles' not in response:\n",
    "            return pd.DataFrame()\n",
    "        articles = []\n",
    "        for article in response['articles']:\n",
    "            content = f\"{article['title']} {article['description']}\"\n",
    "            parsed_date = datetime.strptime(article['publishedAt'], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            articles.append({\n",
    "                'date': parsed_date,\n",
    "                'content': content,\n",
    "                'source': article['source']['name'],\n",
    "                'url': article['url'],\n",
    "                'sentiment': self.analyze_sentiment(content)\n",
    "            })\n",
    "        return pd.DataFrame(articles)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching NewsAPI articles: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newsapi_articles(self, ticker, days_back=7):\n",
    "    if not self.newsapi_key:\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days_back)\n",
    "        response = self.newsapi_client.get_everything(\n",
    "            q=ticker,\n",
    "            from_param=start_date.strftime('%Y-%m-%d'),\n",
    "            to=end_date.strftime('%Y-%m-%d'),\n",
    "            language='en',\n",
    "            sort_by='relevancy'\n",
    "        )\n",
    "        if not response or 'articles' not in response:\n",
    "            return pd.DataFrame()\n",
    "        articles = []\n",
    "        for article in response['articles']:\n",
    "            content = f\"{article['title']} {article['description']}\"\n",
    "            parsed_date = datetime.strptime(article['publishedAt'], \"%Y-%m-%dT%H:%M:%SZ\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            articles.append({\n",
    "                'date': parsed_date,\n",
    "                'content': content,\n",
    "                'source': article['source']['name'],\n",
    "                'url': article['url'],\n",
    "                'sentiment': self.analyze_sentiment(content)\n",
    "            })\n",
    "        return pd.DataFrame(articles)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching NewsAPI articles: {str(e)}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5922188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_news(self, ticker, start_date, end_date):\n",
    "        \"\"\"Returns mock news data from sample_news.json\"\"\"\n",
    "        try:\n",
    "            news_items = []\n",
    "            sample_path = os.path.join(os.path.dirname(__file__), 'sample_news.json')\n",
    "            if not os.path.exists(sample_path):\n",
    "                print(f\"Warning: Mock data file {sample_path} not found\")\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "            with open(sample_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    item = json.loads(line.strip())\n",
    "                    item_date = datetime.strptime(item['date'], '%Y-%m-%dT%H:%M:%S%z')\n",
    "                    item['date'] = item_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    news_items.append(item)\n",
    "            \n",
    "            df = pd.DataFrame(news_items)\n",
    "            \n",
    "            # Filter by date range\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            mask = (df['date'] >= pd.to_datetime(start_date)) & (df['date'] <= pd.to_datetime(end_date))\n",
    "            df = df[mask]\n",
    "            \n",
    "            # Filter by ticker if specified\n",
    "            if ticker:\n",
    "                df = df[df['content'].str.contains(ticker, case=False)]\n",
    "                \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading mock news: {str(e)}\")\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_data(self, ticker, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Get news and sentiment data from all available sources for a given ticker between start and end dates.\n",
    "        Returns a pandas DataFrame with normalized data from all sources.\n",
    "        \"\"\"\n",
    "        if self.use_mock:\n",
    "            df = self.get_mock_news(ticker, start_date, end_date)\n",
    "            if not df.empty:\n",
    "                print(f\"[DEV MODE] Found {len(df)} news items between {start_date} and {end_date}\")\n",
    "            return df\n",
    "        \n",
    "        # Get news from all available sources\n",
    "        dfs = []\n",
    "        \n",
    "        # Alpha Vantage news\n",
    "        av_news = self.get_alpha_vantage_news(ticker)\n",
    "        if not av_news.empty:\n",
    "            av_news['source_type'] = 'alpha_vantage'\n",
    "            dfs.append(av_news)\n",
    "        \n",
    "        # NewsAPI articles\n",
    "        news_articles = self.get_newsapi_articles(ticker)\n",
    "        if not news_articles.empty:\n",
    "            news_articles['source_type'] = 'newsapi'\n",
    "            dfs.append(news_articles)\n",
    "        \n",
    "        # Combine all sources\n",
    "        if not dfs:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "        \n",
    "        # Filter by date range\n",
    "        mask = (combined_df['date'] >= pd.to_datetime(start_date)) & (combined_df['date'] <= pd.to_datetime(end_date))\n",
    "        return combined_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d266f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(self, text):\n",
    "        \"\"\"Analyze sentiment of text using VADER\"\"\"\n",
    "        return self.analyzer.polarity_scores(str(text))['compound']\n",
    "\n",
    "def get_avg_sentiment(self, df):\n",
    "    \"\"\"Calculate average sentiment from a DataFrame of news items\"\"\"\n",
    "    if df.empty:\n",
    "        return 0.0\n",
    "    if 'sentiment' not in df.columns:\n",
    "        df['sentiment'] = df['content'].apply(self.analyze_sentiment)\n",
    "    return df['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob Sentiment Labeler \n",
    "from textblob import TextBlob\n",
    "\n",
    "def analyze_sentiment_label(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of a given text using TextBlob.\n",
    "\n",
    "    Returns:\n",
    "        str: Sentiment label with emoji.\n",
    "    \"\"\"\n",
    "    blob = TextBlob(str(text))\n",
    "    polarity = blob.sentiment.polarity\n",
    "\n",
    "    if polarity > 0.1:\n",
    "        return \"ğŸ˜Š Positive\"\n",
    "    elif polarity < -0.1:\n",
    "        return \"ğŸ˜  Negative\"\n",
    "    else:\n",
    "        return \"ğŸ˜ Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusable VADER function \n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment_vader(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment of a given text using VADER.\n",
    "    Returns a compound score between -1.0 and 1.0.\n",
    "    \"\"\"\n",
    "    return vader.polarity_scores(str(text))['compound']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
